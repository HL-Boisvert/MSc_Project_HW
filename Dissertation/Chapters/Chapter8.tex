% Chapter 8

\chapter{Conclusions} % Main chapter title

\label{Chapter8} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 8. \emph{Conclusions}}

%----------------------------------------------------------------------------------------

\section{Reflexions}
\subsection{Hypothesis n°1}
\label{reflexions_h1}
When looking at the comparison between the lap time, average minimal LiDAR distance and average acceleration/deceleration metrics on the RedBull track (Figures \ref{h1_time}, \ref{h1_lidar}, \ref{h1_accel} and \ref{h1_decel}), we can draw 3 conclusions regarding Hypothesis n°1 (\textit{Deep Reinforcement Learning provides a real advantage, quantified by reliable metrics, for controlling an F1Tenth car over human control and PID-based methods like wall following.}):
\begin{itemize}
	\item  Regarding the speed metric (time to complete a full lap), Hypothesis n°1 appears to be verified for 2 DQN controllers: the CNN with reward functions n°2 and 3, with the latter performing the best. The hypothesis may also be verified for a NN with reward function n°2, but the experimental uncertainty is too high to confirm this result.
	\item Regarding the safety metric (average minimum LiDAR distance), Hypothesis n°1 appears to be verified for all DQN controllers apart from the NN with reward function n°1. The best performing controllers are the CNNs, with the reward function n°3 being the best.
	\item Regarding the smoothness metric (average acceleration/deceleration), Hypothesis n°1 is only verified by the CNN with reward function n°3 when looking at the average deceleration metric but is verified by all DQN controllers apart from CNN with reward function n°2 when looking at the average acceleration. 
\end{itemize}

Hypothesis n°1 can then be checked using the P-Value method (more details are available in the Excel file): \\

\begin{itemize}
	\item \textbf{Null Hypothesis (H0)}: There is no real advantage provided by CNNs with reward functions 2 and 3 over Wall Following. 
	\item \textbf{Alternative hypothesis (H1)}: CNNs provide a real advantage with reward functions 2 and 3 over Wall Following.
\end{itemize}

Using the standard value of Alpha = 0.05 and an independent two-tailed T-test, we obtained the following results:

\begin{itemize}
	\item Time metric: comparing the 10-lap sample with reward function n°2 to the 10-lap sample with Wall Following gives $p-value=1,81 \cdot 10^{-12}<0,05$, which means the result is significant, and the Null Hypothesis can be rejected. With the reward function n°3, we get $p-value=7,29 \cdot 10^{-16}<0,05$: the result is also significant.
	\item Average acceleration metric: comparing the 10-lap sample with reward function n°2 to the 10-lap sample with Wall Following gives $p-value=1,14 \cdot 10^{-22}<0,05$, which means the result is significant, and the Null Hypothesis can be rejected. With the reward function n°3, we get $p-value=6,56 \cdot 10^{-10}<0,05$: the result is also significant.
	\item Average deceleration metric: comparing the 10-lap sample with reward function n°2 to the 10-lap sample with Wall Following gives $p-value=0,0094<0,05$, which means the result is significant, and the Null Hypothesis can be rejected. With the reward function n°3, we get $p-value=6,64 \cdot 10^{-23}<0,05$: the result is also significant.
	\item Average minimal LiDAR distance metric: comparing the 10-lap sample with reward function n°2 to the 10-lap sample with Wall Following gives $p-value=2,83 \cdot 10^{-18}<0,05$, which means the result is significant and the Null Hypothesis can be rejected. With the reward function n°3, we get $p-value=1,42 \cdot 10^{-22}<0,05$: the result is also significant.
\end{itemize} 

To conclude, the only DQN controller which verifies Hypothesis n°1 for the speed, safety, and smoothness metrics is the CNN with reward function n°3. This shows that in order to be efficient, a DQN controller has to be trained using a carefully chosen reward function and that with the limited training time used in the experimental protocol NNs don't verify the hypothesis. \\
However, it is likely that for a longer training time, the DQN would have been able to perform better, as the average reward during an evaluation epoch of several of the controllers was still increasing towards the end of the training, especially CNNs with reward functions 2 and 3 (Figure \ref{comparison_eval}). For those two controllers, the reward increased by over 30\% during the last 30 evaluation epochs, unlike the other controllers, which didn't show any significant reward increase over that time.

\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.65\textwidth]{Figures/H1_Time.png}
        \caption{Lap time comparison for controllers on the RedBull track}
        \label{h1_time}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.65\textwidth]{Figures/H1_LiDAR.png}
        \caption{Average minimal LiDAR distance for controllers on the RedBull track}
        \label{h1_lidar}
    \end{minipage}
\end{figure}

\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.65\textwidth]{Figures/H1_accel.png}
        \caption{Average acceleration comparison for controllers on the RedBull track}
        \label{h1_accel}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.65\textwidth]{Figures/H1_decel.png}
        \caption{Average deceleration comparison for controllers on the RedBull track}
        \label{h1_decel}
    \end{minipage}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.65]{Figures/eval_score.png}
	\caption{Comparison of average rewards on an evaluation epoch in function of the epoch for the different DQN controllers}
	\label{comparison_eval}
\end{figure}

\subsection{Hypothesis n°2}
When looking at the comparison between the lap time, average minimal LiDAR distance and average acceleration/deceleration metrics on the RedBull track (Figures \ref{h1_time}, \ref{h1_lidar}, \ref{h1_accel} and \ref{h1_decel}), we can draw 3 conclusions regarding Hypothesis n°2 (\textit{CNNs offer better results over selected metrics than NNs for autonomous racing on the F1Tenth platform using data from a UST-10LX LiDAR.}):
\begin{itemize}
	\item Regarding the speed metric (time to complete a full lap), Hypothesis n°2 is verified: for each reward function, the CNN controller performs better than the NN controller.
	\item Regarding the safety metric (average minimum LiDAR distance), Hypothesis n°2 is also verified: for each reward function, the CNN controller performs better than the NN controller.
	\item Regarding the smoothness metric (average acceleration/deceleration), Hypothesis n°2 is verified for reward functions 1 and 2.
\end{itemize}

Hypothesis n°2 was then checked using the P-Value method, similarly to \ref{reflexions_h1}, using the following hypotheses:

\begin{itemize}
	\item \textbf{Null Hypothesis (H0)}: There is no real advantage provided by CNNs over NNs using the same reward function.
	\item \textbf{Alternative hypothesis (H1)}: There is a real advantage provided by CNNs over NNs using the same reward function.
\end{itemize}

Using the standard value of Alpha = 0.05 and an independent two-tailed T-test, the results for all metrics were found to be significant; more details are available in the Excel file. \\
To conclude, Hypothesis n°2 is verified for all metrics and reward functions apart from reward function 3 for the smoothness metric.

\subsection{Hypothesis n°3}
Hypothesis n°3 (\textit{DRL-based controllers can generalise to new race tracks without affecting too much the metrics}) was verified by comparing on the Monaco track the performance of the CNNs trained on the RedBull track to those trained on the Monaco track. The results are introduced in Table \ref{hyp3}.

\begin{table}[H]
\centering
\begin{tabularx}{\textwidth}{||X|X|X|X|X|X|X||} 
\hline
 Controller & Total Time ($s$) & Average Positive Acceleration ($m/s^2$)& Average Negative Acceleration ($m/s^2$) & Maximum Acceleration ($m/s^2$) & Maximum Deceleration ($m/s^2$) & Average Minimum LiDAR Range ($m$)\\ [0.5ex] 
 \hline\hline
 CNN R2 Monaco Trained & 42,28 & 0,93 & -1,25 & 5,18 & -6,67 & 0,80\\[0.5ex] 
 \hline
 CNN R3 Monaco Trained & 40,91 & 0,84 & -1,14 & 4,34 & -2,69 & 0,83\\[0.5ex] 
 \hline
CNN R2 RedBull Trained & 46,74 & 0,90 & -1,29 & 5,24 & -6,58 & 0,78\\[0.5ex] 
 \hline
 CNN R3 RedBull Trained & 44,98 & 0,89 & -1,10 & 4,30 & -2,94 & 0,77\\[0.5ex] 
 \hline
 \end{tabularx}
\caption{Experimental results on the Monaco Track comparing DQN controllers trained on Monaco or RedBull tracks}
\label{hyp3}
\end{table}

The P-values were then calculated, still using the standard value of Alpha = 0.05 and an independent two-tailed T-test (Table \ref{pvalues}).

\begin{table}[H]
\centering
\begin{tabularx}{\textwidth}{||X|X|X|X|X|X|X||} 
\hline
 Metric & Reward Function 2 & Reward function 3\\ [0.5ex] 
 \hline\hline
Time ($s$) & 0,99$>$0,05 & 0,64$>$0,05\\[0.5ex] 
 \hline
Average Positive Acceleration ($m/s^2$) & 0,74$>$0,05 & 0,98$>$0,05\\[0.5ex] 
 \hline
 Average Negative Acceleration ($m/s^2$)  & 0,77$>$0,05 & 0,34$>$0,05\\[0.5ex] 
 \hline
 Average Minimal LiDAR distance ($m$) & 0,91$>$0,05 & 0,93$>$0,05\\[0.5ex] 
 \hline
\end{tabularx}
\caption{P-Values for all metrics on Monaco Track when comparing DQN controllers trained on Monaco or RedBull tracks}
\label{pvalues}
\end{table}

All P-Values are larger than 0,05, meaning that the DQN controllers don't generalise perfectly, which proves that Hypothesis n°3 is false. However, the CNNs are still performing better than the Wall Following on all metrics.

\subsection{Hypothesis n°4}
Concerning Hypothesis n°4 (\textit{The sim2Real gap is negligible (minor changes of the metrics) and doesn't affect the performance of the controllers implemented.}), we first looked at the Wall Following controller. once the PID was tuned it was found there was no significant Sim2Real gap, with $p-value=0,019<0,05$ for the speed metric and $p-value=0,039<0,05$ for the safety metric. \\
Looking at the CNN with reward function n°3, there was also no significant Sim2Real gap, with $p-value=0,046$ for the speed metric and $p-value=0,033$ for the safety metric. \\ 
There are four limitations to Hypothesis n°4:
\begin{enumerate}
	\item The lack of the speed input because of the unreliable odometry, which means the metrics that depended on the speed measurement couldn't be assessed
	\item The lack of data for a complete lap of the track with the DQN controller
	\item The lack of data at speeds higher than 4m/s
	\item The lack of data for DQN controllers other than the CNN with reward function n°3
\end{enumerate}

\section{Future works}
This dissertation introduced a well-defined protocol in \ref{Chapter6}; because this 
experimental protocol is quite flexible, the process could be extended to other DRL state-of-the-art methods, such as DDPG and TD3, following the same methodology. \\
A first improvement to the experimental protocol would be to fine-tune the different DQN hyper-parameters: learning rate $\alpha$, discount factor $\gamma$, greediness $epsilon$, epsilon decay, and size of the replay buffer. This would make sure that the training process is as efficient as possible. \\
A second improvement would be to train the controllers for longer to then test their limits; this couldn't be done due to hardware and time constraints. \\
A third improvement to the experimental protocol would be verifying hypothesis n°3 more rigorously. The protocol used here to verify this hypothesis was to train the DQN controller on the RedBull racetrack before testing it on the Silverstone and Monaco tracks. The underlying assumption was that those three tracks offered a comparable level of challenge, but this hasn't been proven. Because the underlying assumption may be false, it makes the assessment unreliable. A way to improve this would be by defining a metric to quantify the difficulty offered by a specific race track based on the length, minimal track width and minimum curve radius. This could be implemented using a Support Vector Machine (SVM) with the shape of the track as an input, as introduced in \cite{futurework}.\\
A fourth improvement to the experimental protocol would be to develop a more advanced simulator to perform the training, for example, by using a more accurate kinematic model rather than the Bicycle model we used.